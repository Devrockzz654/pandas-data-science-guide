{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74270b3b-9a71-4b03-9f6e-98643b90770f",
   "metadata": {},
   "source": [
    "<center><h1>Data Handling and Analysis with Pandas: A Comprehensive Guide for Data Science Professionals</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7d845-1e82-4d01-9743-5a22fd3fb70c",
   "metadata": {},
   "source": [
    "# 1. Getting Familiar with Pandas\n",
    "\n",
    "## Introduction to Pandas:\n",
    "Pandas is an open-source data manipulation and analysis library for Python. It is built on top of NumPy and provides high-level data structures and methods designed to make data analysis fast and easy. The two primary data structures in Pandas are:\n",
    "\n",
    "- **Series:** A one-dimensional array that can hold any data type (integers, strings, floats, etc.). It is like a column in a table.\n",
    "- **DataFrame:** A two-dimensional, tabular data structure with labeled axes (rows and columns). It can be thought of as a collection of Series objects.\n",
    "\n",
    "## Understanding DataFrames and Series\n",
    "\n",
    "- **Series:**\n",
    "A Pandas Series is similar to a list or a one-dimensional array in Python. Each element in a Series is assigned a label (also known as an index), which allows for easy access to individual elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fceb9413-1838-47db-8640-f703ae0c6cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1    200\n",
      "Q2    300\n",
      "Q3    400\n",
      "Q4    500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a Series from a list\n",
    "sales = pd.Series([200, 300, 400, 500], index=['Q1', 'Q2', 'Q3', 'Q4'])\n",
    "\n",
    "print(sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5606bd-88c4-419d-83ff-8a31329cba11",
   "metadata": {},
   "source": [
    "Here, Q1, Q2, Q3, and Q4 are labels (index) for each element in the Series. This index can be customized as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f53b54-3e58-4a85-86d4-962791c10f13",
   "metadata": {},
   "source": [
    "- **DataFrame:**\n",
    "\n",
    "  A DataFrame is essentially a collection of Series, each one representing a column. It is analogous to a spreadsheet or SQL table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6663a2a9-abb1-4c0a-aaea-032dcf134f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a dictionary of lists\n",
    "data = {'Name': ['John', 'Anna', 'Peter'],\n",
    "        'Age': [28, 24, 35],\n",
    "        'City': ['New York', 'Paris', 'Berlin']}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6359de84-10b5-4a03-9b74-90bd8f4ee1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age      City\n",
      "0   John   28  New York\n",
      "1   Anna   24     Paris\n",
      "2  Peter   35    Berlin\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae7b77f-8619-4e6c-b15b-fbdb42800ae4",
   "metadata": {},
   "source": [
    "Each column in the DataFrame is a Series, and the DataFrame allows for easy manipulation and analysis of tabular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691df27d-ce2d-4910-a1ff-96f884863de8",
   "metadata": {},
   "source": [
    "## Creating DataFrames and Series from Various Sources\n",
    "\n",
    "- **From Lists and Dictionaries:**\n",
    "\n",
    "  Pandas makes it easy to create Series and DataFrames from Python lists and dictionaries, providing flexibility in how you organize and input your \n",
    "  data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "685c12b8-db06-45b7-9b75-4efc30a1c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a Series from a dictionary\n",
    "population = pd.Series({'New York': 8419000, 'Los Angeles': 3980000, 'Chicago': 2716000})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bf43595-7fa9-4d3f-b32f-5bf70c617146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a dictionary of Series\n",
    "data = {\n",
    "    'Population': population,\n",
    "    'Area': pd.Series({'New York': 789, 'Los Angeles': 503, 'Chicago': 589})\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "323c056e-acd6-4b6d-be63-318e341cea82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Population  Area\n",
      "New York        8419000   789\n",
      "Los Angeles     3980000   503\n",
      "Chicago         2716000   589\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfbd358-77f5-41b9-8acb-7c16ff986448",
   "metadata": {},
   "source": [
    "- **From CSV Files:**\n",
    "\n",
    "  CSV files are one of the most common data formats, and Pandas provides convenient methods to load data from CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6a866a6-8bbf-4db9-bdf0-c4fb7bbb0334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age      City  Salary\n",
      "0   John   28  New York   50000\n",
      "1   Anna   24     Paris   62000\n",
      "2  Peter   35    Berlin   70000\n",
      "3  Linda   32     Tokyo   56000\n",
      "4  James   40    Sydney   65000\n"
     ]
    }
   ],
   "source": [
    "# Loading data from a CSV file\n",
    "df_csv = pd.read_csv('data.csv')\n",
    "\n",
    "print(df_csv.head())  # Display the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4434b7b-74ca-4b4f-bcf1-2a45ee21d1bb",
   "metadata": {},
   "source": [
    "Explanation: The read_csv() function is extremely powerful, allowing you to specify parameters such as column names, index columns, missing value indicators, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd847f6-b873-4afe-b731-40ebbb19bb99",
   "metadata": {},
   "source": [
    "## Common Operations with DataFrames\n",
    "\n",
    "- **Selecting Data:**\n",
    " \n",
    "  Selecting specific rows or columns from a DataFrame is a fundamental operation, useful in filtering data for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8b5782e-040e-4902-b830-6a2b184b5e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a single column\n",
    "cities = df_csv['City']\n",
    "\n",
    "# Selecting multiple columns\n",
    "name_age = df_csv[['Name', 'Age']]\n",
    "\n",
    "# Selecting rows using index labels (loc)\n",
    "john_info = df_csv.loc[0]\n",
    "\n",
    "# Selecting rows using integer location (iloc)\n",
    "anna_info = df_csv.iloc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eae607e-976d-4b0e-8747-26a46b6590d2",
   "metadata": {},
   "source": [
    "- **Filtering Rows:**\n",
    "\n",
    "  Filtering data allows you to focus on subsets of your data that meet certain criteria, which is essential for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd9cac3-89b7-473e-ab39-ab5733dbc6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering rows where Age > 30\n",
    "age_filtered_df = df_csv[df_csv['Age'] > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c31b28-ae1b-4b14-a70b-448cc12bc66d",
   "metadata": {},
   "source": [
    "- **Modifying Data:**\n",
    "\n",
    "  Pandas allows you to add, modify, or delete columns with ease, making it simple to adjust your dataset as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6e4738-9c25-4b5b-b54e-17f02490cae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column based on existing data\n",
    "df_csv['Age in 5 Years'] = df_csv['Age'] + 5\n",
    "\n",
    "# Modifying existing data\n",
    "df_csv['City'] = df_csv['City'].replace('New York', 'NYC')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1a4a4-d5b5-4e7e-b9ef-721954683540",
   "metadata": {},
   "source": [
    "# 2. Data Handling with Pandas\n",
    "\n",
    "## Reading and Handling Data:\n",
    "\n",
    "- **Reading Data from Files:**\n",
    "\n",
    "  Pandas supports reading data from various file formats, including CSV, Excel, and JSON. This versatility is crucial for data professionals who \n",
    "  work with diverse data sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be2aae2f-0ea5-40ee-9a6c-e1077254f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from a CSV file\n",
    "df_csv = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6e5c93-57b7-494a-98a8-f619f1cd50cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading from an Excel file\n",
    "df_excel = pd.read_excel('data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0824f1-ca5d-4bb5-948f-dcc9cce91e3c",
   "metadata": {},
   "source": [
    "Explanation: The ability to read from multiple file types ensures that Pandas can integrate seamlessly with different data ecosystems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07132eaf-14b0-4c9f-b862-cb079a736868",
   "metadata": {},
   "source": [
    "- **Handling Missing Data:**\n",
    "\n",
    "  Missing data is a common issue in real-world datasets, and Pandas offers robust tools to identify, fill, or remove missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c25c05a-84b3-4bc3-875a-744c9ac71351",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lw/9_gcjfzs13bbbm4k28hnvhz00000gn/T/ipykernel_27286/1250012900.py:8: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df_ffill = df.fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing data\n",
    "missing_data = df_csv.isnull().sum()\n",
    "\n",
    "# Filling missing values with a specified value\n",
    "df_filled = df_csv.fillna(0)\n",
    "\n",
    "# Forward fill to propagate the last valid observation forward\n",
    "df_ffill = df.fillna(method='ffill')\n",
    "\n",
    "# Dropping rows with any missing values\n",
    "df_dropped = df_csv.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56923f39-5eb3-4aa0-8162-2c5a2b12a4be",
   "metadata": {},
   "source": [
    "Explanation: Efficient handling of missing data is critical for ensuring that your analyses are accurate and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7eecad-6425-4d1e-886c-758e743ff592",
   "metadata": {},
   "source": [
    "- **Transforming Data:**\n",
    "\n",
    "  Data transformation is often necessary to prepare data for analysis or modeling. Pandas makes it easy to convert data types, remove duplicates, \n",
    "  and perform other transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8d00b69-12c2-4892-99e2-5261271ea136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting data types\n",
    "df_csv['Age'] = df_csv['Age'].astype(float)\n",
    "\n",
    "# Removing duplicates\n",
    "df_unique = df.drop_duplicates()\n",
    "\n",
    "# Renaming columns\n",
    "df_renamed = df_csv.rename(columns={'Age': 'Years'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc1672-e739-4460-8ff1-b0c6a89697f9",
   "metadata": {},
   "source": [
    "Explanation: These transformations help in standardizing data, ensuring consistency, and making the data more suitable for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab59460-a203-4f44-a6f4-fc25a9f9d293",
   "metadata": {},
   "source": [
    "# 3. Data Analysis with Pandas\n",
    "\n",
    "## Performing Data Analysis:\n",
    "\n",
    "- **Generating Summary Statistics:**\n",
    "  \n",
    "  Summary statistics provide a quick overview of your data, allowing you to understand the central tendency, dispersion, and distribution of your \n",
    "  data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36492902-0b5f-4637-bae7-977b8e6d4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Numerical summary statistics\n",
    "numeric_summary = df_csv.describe()\n",
    "\n",
    "# Categorical summary statistics\n",
    "categorical_summary = df_csv.describe(include=['object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b96a164-be6d-48fe-a6f3-39c4ae38d1ed",
   "metadata": {},
   "source": [
    "Explanation: These statistics are often the first step in exploratory data analysis (EDA), giving you a sense of your dataset’s structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe4faf4-2c89-437b-a83a-e9bf34feb703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by a single column\n",
    "grouped = df_csv.groupby('City')\n",
    "\n",
    "# Calculating the mean for each group\n",
    "group_mean = grouped.mean()\n",
    "\n",
    "# Applying multiple aggregate functions\n",
    "group_aggregate = grouped.agg({'Age': ['mean', 'max'], 'Salary': 'sum'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f7107f-3db2-48b1-8db0-18adac9292d4",
   "metadata": {},
   "source": [
    "Explanation: Grouping is essential in cases where you need to analyze data across different categories or segments, such as sales data by region or customer data by demographics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea97fce-b9c5-4040-b59a-91cf6a2998e8",
   "metadata": {},
   "source": [
    "- **Advanced Data Manipulation:**\n",
    " \n",
    "  Advanced techniques such as merging, joining, and concatenating DataFrames are crucial when working with multiple \n",
    "  datasets, allowing you to combine and organize data from different sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b700e369-4133-4c9d-8dc9-102c7fdcdc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging DataFrames\n",
    "df1 = pd.DataFrame({'ID': [1, 2, 3], 'Name': ['John', 'Anna', 'Peter']})\n",
    "df2 = pd.DataFrame({'ID': [1, 2, 4], 'City': ['NYC', 'Paris', 'Berlin']})\n",
    "merged_df = pd.merge(df1, df2, on='ID', how='inner')\n",
    "\n",
    "# Joining DataFrames\n",
    "df_joined = df1.join(df2.set_index('ID'), on='ID')\n",
    "\n",
    "# Concatenating DataFrames along rows or columns\n",
    "df_concat = pd.concat([df1, df2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee2af1-6924-47f1-b0e9-d0165275d342",
   "metadata": {},
   "source": [
    "Explanation: These operations are common in data engineering pipelines, where data from various sources needs to be integrated and prepared for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2338512e-63e8-4572-9bca-15126e49bf65",
   "metadata": {},
   "source": [
    "# 4. Application in Data Science\n",
    "\n",
    "## Advantages of Using Pandas in Data Science:\n",
    "\n",
    "Pandas is an essential tool for data scientists due to its ability to handle large datasets, perform complex data manipulations, and integrate seamlessly with other data science libraries such as NumPy, Matplotlib, and scikit-learn. Here are some key advantages:\n",
    "\n",
    "- **Efficiency:** Pandas is built on top of NumPy, which allows it to handle large datasets efficiently. Operations on DataFrames and Series are vectorized, meaning that they are executed in a highly optimized manner, often using C or Fortran under the hood. This makes Pandas significantly faster than using pure Python data structures like lists or dictionaries for numerical computations.\n",
    "- **Ease of Use:** The API of Pandas is user-friendly and intuitive, allowing data scientists to perform complex data manipulations with minimal code. For example, filtering, aggregating, and transforming data can be done in a few lines, which speeds up the data analysis process.\n",
    "- **Integration with Other Libraries: Pandas works seamlessly with other Python libraries commonly used in data science, such as:**\n",
    "\t-\t**NumPy:** For numerical operations.\n",
    "\t-\t**Matplotlib/Seaborn:** For data visualization.\n",
    "\t-\t**scikit-learn:** For machine learning.\n",
    "\t-\t**Statsmodels:** For statistical modeling.\n",
    "\t-\t**Data Cleaning and Preprocessing:** Data scientists spend a significant amount of time cleaning and preprocessing data. Pandas provides robust tools for handling missing values, filtering outliers, and transforming data types, making it easier to prepare data for analysis or machine learning models.\n",
    "- **Exploratory Data Analysis (EDA):** Pandas is widely used for EDA, which involves summarizing the main characteristics of a dataset, often using visual methods. With Pandas, you can quickly generate summary statistics, create pivot tables, and visualize data distributions, helping you to uncover patterns, relationships, and anomalies in your data.\n",
    "\n",
    "## Real-World Examples of Pandas in Action:\n",
    "\n",
    "-\t**1.\tData Cleaning in Financial Analysis:**\n",
    "\t-\t**Scenario:** A financial analyst is working with stock market data that contains missing values, outliers, and inconsistent data types.\n",
    "\t-\t**Pandas Application:** The analyst uses Pandas to clean the data by filling missing values with forward fill, removing outliers using quantile-based filtering, and converting data types to ensure consistency. After cleaning, the analyst can perform time series analysis to forecast stock prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d189adc3-5e1c-450c-aa9f-f08aaae0ab12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward filling missing values\n",
    "df['Close'] = df['Close'].fillna(method='ffill')\n",
    "\n",
    "# Removing outliers\n",
    "q_low = df['Close'].quantile(0.01)\n",
    "q_high = df['Close'].quantile(0.99)\n",
    "df_filtered = df[(df['Close'] > q_low) & (df['Close'] < q_high)]\n",
    "\n",
    "# Converting data types\n",
    "df['Date'] = pd.to_datetime(df['Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364073f-5b6b-4430-826f-e8d89b146091",
   "metadata": {},
   "source": [
    "## 2.\tExploratory Data Analysis (EDA) in Customer Segmentation:\n",
    "-\t**Scenario:** A marketing team wants to segment their customer base based on purchasing behavior to tailor marketing campaigns.\n",
    "-\t**Pandas Application:** Using Pandas, the team can group customers by their purchase frequency, average transaction value, and product categories. This grouped data is then used to create segments such as “high-value customers” or “frequent buyers,” allowing the marketing team to target each segment more effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1031a871-731f-4688-a502-e1c75f81a5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping customers by purchase frequency and average transaction value\n",
    "customer_segments = df.groupby('CustomerID').agg({\n",
    "    'PurchaseAmount': 'mean',\n",
    "    'TransactionID': 'count'\n",
    "}).rename(columns={'PurchaseAmount': 'AvgPurchaseValue', 'TransactionID': 'PurchaseFrequency'})\n",
    "\n",
    "# Creating customer segments based on thresholds\n",
    "high_value_customers = customer_segments[customer_segments['AvgPurchaseValue'] > 1000]\n",
    "frequent_buyers = customer_segments[customer_segments['PurchaseFrequency'] > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091b3ad-b2d2-4d45-8899-3117ad57dd8f",
   "metadata": {},
   "source": [
    "## 3.\tMerging Datasets in Scientific Research:\n",
    "-\t**Scenario:** A researcher needs to combine multiple datasets from different sources to analyze the impact of environmental factors on health outcomes.\n",
    "-\t**Pandas Application:** The researcher uses Pandas to merge datasets containing demographic information, environmental data, and health records. After merging, the researcher can apply statistical models to analyze correlations and causations between environmental factors and health outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1038eea1-00fe-4eb1-8950-5e2f3423274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging environmental data with health records\n",
    "merged_data = pd.merge(env_data, health_data, on='RegionID', how='inner')\n",
    "\n",
    "# Analyzing correlation between pollution levels and health outcomes\n",
    "correlation = merged_data[['PollutionLevel', 'HealthScore']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f71bec6-7fe2-4592-bc83-833b53292347",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Pandas is a versatile and powerful tool that plays a critical role in data science workflows. Its ability to efficiently handle, manipulate, and analyze large datasets makes it indispensable for data scientists. Whether it’s cleaning messy data, performing complex data analysis, or integrating multiple data sources, Pandas provides the tools needed to streamline and enhance these processes.\n",
    "\n",
    "# Summary of Findings\n",
    "\n",
    "-\tPandas simplifies data manipulation with its intuitive API, allowing for quick and efficient data cleaning, transformation, and analysis.\n",
    "-\tIts integration with other Python libraries makes it a cornerstone of the Python data science ecosystem, enabling seamless workflows from data ingestion to model deployment.\n",
    "-\tReal-world applications of Pandas highlight its importance in tasks such as financial analysis, customer segmentation, and scientific research, demonstrating its versatility across various domains.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (hello)",
   "language": "python",
   "name": "hello"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
